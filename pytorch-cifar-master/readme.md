# 实验环境
- numpy==1.26.4  
- torchvision==0.20.1  
- timm==1.0.13  
- pillow==11.1.0  
- yaml==0.2.5  
- pyyaml==6.0.2  
- matplotlib==3.10.0  
- tqdm==4.67.1
---
# 数据集下载
[CIFAR-100 Python](https://www.kaggle.com/datasets/fedesoriano/cifar100/data)
---
# 运行方式
先将下载好的数据集整个放入data文件

## 如果你想从头开始训练
python cifar_main.py

## 如果你想从checkpoint开始
python cifar_main.py --resume

**其余参数可以参照程序进行修改，默认参数已经设定好**

---
# # 实验结果

| 优化算法 | 最高测试集准确率 (%) | 出现轮次 (Epoch) | 收敛速度 | 泛化能力 | 过拟合现象 |
|----------|-----------------------|------------------|----------|----------|------------|
| SGD      | 60.61                | 185              | 中等     | 良好     | 较为明显   |
| Adam     | 58.27                | 161              | 快       | 较差     | 较严重     |
| SAM      | 61.67                | 195              | 较慢     | 优秀     | 轻微       |

## 详细描述

### SGD 优化算法
- **最高测试集准确率**：60.61%，出现在第185轮。
- **特点**：训练损失逐步下降，测试损失波动较大。过拟合现象在第25轮后逐渐显现。
- **优势**：收敛后具有较高的泛化性能。
- **劣势**：收敛速度较慢，训练过程中波动明显。

### Adam 优化算法
- **最高测试集准确率**：58.27%，出现在第161轮。
- **特点**：损失曲线平滑，收敛速度快，但泛化能力较差。过拟合现象在第28轮后加剧。
- **优势**：收敛速度快，适合资源紧张的场景。
- **劣势**：过拟合较严重，测试集性能低于SGD。

### SAM 优化算法
- **最高测试集准确率**：61.67%，出现在第195轮。
- **特点**：训练损失下降较快，测试损失波动逐渐减小。过拟合现象较轻，泛化能力显著增强。
- **优势**：在缓解过拟合问题和提高泛化性能方面表现最佳。
- **劣势**：收敛速度较慢，计算成本较高。

